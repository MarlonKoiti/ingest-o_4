{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "import pandas as pd\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col,regexp_replace\nimport pyarrow as pa\nimport pyarrow.parquet as pq",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.38.1 \nAuthenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::218606466161:role/LabRole\nTrying to create a Glue session for the kernel.\nWorker Type: G.1X\nNumber of Workers: 5\nSession ID: 0d368737-f7af-4283-8875-19db2142897d\nJob Type: glueetl\nApplying the following default arguments:\n--glue_kernel_version 0.38.1\n--enable-glue-datacatalog true\nWaiting for session 0d368737-f7af-4283-8875-19db2142897d to get into ready status...\nSession 0d368737-f7af-4283-8875-19db2142897d has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Inicialize a sess√£o Spark\nspark = SparkSession.builder \\\n    .appName(\"ReadS3DataJoin\") \\\n    .getOrCreate()\n\ninput_s3_path_bancos = \"s3://218606466161-trusted/Bancos/*.parquet\"\ninput_s3_path_empregados = \"s3://218606466161-trusted/Empregados/*.parquet\"\ninput_s3_path_reclamacoes = \"s3://218606466161-trusted/Reclamacoes/*.parquet\"\n\noutput_s3_path_delivery = \"s3://218606466161-delivery/bancos_satisfacao\"\n\ndf_bancos = spark.read.option(\"encoding\", \"UTF-8\").parquet(input_s3_path_bancos)\ndf_empregados = spark.read.option(\"encoding\", \"UTF-8\").parquet(input_s3_path_empregados)\ndf_reclamacoes = spark.read.option(\"encoding\", \"UTF-8\").parquet(input_s3_path_reclamacoes)\n\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_join_reclama_empreg = df_empregados.join(df_reclamacoes, on=\"Nome\", how=\"inner\")\nfinal_df = df_join_reclama_empreg.join(df_bancos, on=\"Nome\", how=\"inner\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "final_df.write.format(\"parquet\").mode(\"overwrite\").option(\"path\", f\"{output_s3_path_delivery}\").save()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": null,
			"outputs": []
		}
	]
}